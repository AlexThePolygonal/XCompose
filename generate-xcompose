#!/usr/bin/env python3
"""XCompose generator with Russian keyboard transliteration and collision detection.

Merged single-file version for deployment to /usr/local/bin.
"""

import sys
import json
import os
import locale
import argparse
import unicodedata
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from dataclasses import dataclass, field
from enum import Enum


@dataclass
class XComposeEntry:
    """Single XCompose entry with parsed components."""
    keys: List[str]           # ["i", "a"] from <i> <a>
    symbol: str               # "ð‘Ž"
    unicode_point: str        # "U1D44E"
    description: str          # "MATHEMATICAL ITALIC SMALL A"
    source_file: str                   # Source file name
    line_number: int          # Source line for error reporting


@dataclass
class XComposeBlock:
    """Block of XCompose entries with optional header."""
    header: str                        # Block header text
    entries: List[XComposeEntry]       # Entries in this block


@dataclass
class Collision:
    """Represents a prefix collision between two sequences."""
    prefix_seq: List[str]              # The prefix sequence
    prefix_entry: XComposeEntry        # Entry with the prefix
    prefix_source_file: str            # File where prefix_entry is from
    longer_entry: XComposeEntry        # Entry that has prefix as prefix
    longer_source_file: str            # File where longer_entry is from


@dataclass
class TrieNode:
    """Prefix tree node with optional terminal entry."""
    entry: Optional[XComposeEntry] = None
    children: Dict[str, 'TrieNode'] = field(default_factory=dict)


class CollisionLocation(Enum):
    """Where a collision was detected."""
    INTERNAL = "internal"              # Within same file
    CROSS_SYSTEM = "cross_system"      # Between draft and system
    CROSS_TRANSLIT = "cross_translit"  # In transliterated version


# Type Aliases
KeySequence = List[str]
TranslitMap = Dict[str, str]


# Exceptions
class XComposeError(Exception):
    """Base exception for XCompose generator."""
    pass


class ParseError(XComposeError):
    """Parse error with line number and context."""

    def __init__(self, line_number: int, line_content: str, message: str):
        self.line_number = line_number
        self.line_content = line_content
        self.message = message
        super().__init__(self.__str__())

    def __str__(self) -> str:
        return f"Line {self.line_number}: {self.message}\n  {self.line_content}"


class CollisionError(XComposeError):
    """Collision detected in strict mode."""
    pass


class TranslitError(XComposeError):
    """Transliteration error."""
    pass



def extract_unicode_info(symbol: str) -> Tuple[str, str]:
    """
    Extract Unicode code point and description using unicodedata.

    Args:
        symbol: Unicode character(s)

    Returns:
        (unicode_point, description) e.g. ("U1D44E", "MATHEMATICAL ITALIC SMALL A")
    """
    if len(symbol) == 0:
        return "", "EMPTY"

    # Single character
    codepoint = ord(symbol)
    unicode_point = f"U{codepoint:X}"

    # Raise an error immediately if character is not defined
    description = unicodedata.name(symbol)

    return unicode_point, description


def escape_symbol(symbol: str) -> str:
    """
    Escape symbol for safe display, handling all problematic Unicode cases.

    Returns escaped representation for display, or original symbol if safe.
    """
    if len(symbol) != 1:
        return repr(symbol)  # Multi-char strings get repr

    cp = ord(symbol)

    # 1. COMBINING CHARACTERS (U+0300â€“U+036F, U+1AB0â€“U+1AFF, U+1DC0â€“U+1DFF, U+20D0â€“U+20FF, U+FE20â€“U+FE2F)
    # Add dotted circle â—Œ (U+25CC) before combining chars to show combining action
    if (0x0300 <= cp <= 0x036F or    # Combining Diacritical Marks
        0x1AB0 <= cp <= 0x1AFF or    # Combining Diacritical Marks Extended
        0x1DC0 <= cp <= 0x1DFF or    # Combining Diacritical Marks Supplement
        0x20D0 <= cp <= 0x20FF or    # Combining Diacritical Marks for Symbols
        0xFE20 <= cp <= 0xFE2F):     # Combining Half Marks
        return f"â—Œ{symbol}"

    # 2. CONTROL CHARACTERS (U+0000â€“U+001F, U+007Fâ€“U+009F)
    # Display as U+XXXX since they're invisible
    if (0x0000 <= cp <= 0x001F or
        0x007F <= cp <= 0x009F):
        return f"U+{cp:04X}"

    # 3. WHITESPACE VARIATIONS (invisible or indistinguishable from regular space)
    whitespace_map = {
        0x00A0: "NBSP",           # No-Break Space
        0x1680: "OGHAM-SPACE",    # Ogham Space Mark
        0x2000: "NQSP",           # En Quad
        0x2001: "MQSP",           # Em Quad
        0x2002: "ENSP",           # En Space
        0x2003: "EMSP",           # Em Space
        0x2004: "3/MSP",          # Three-Per-Em Space
        0x2005: "4/MSP",          # Four-Per-Em Space
        0x2006: "6/MSP",          # Six-Per-Em Space
        0x2007: "FSP",            # Figure Space
        0x2008: "PSP",            # Punctuation Space
        0x2009: "THSP",           # Thin Space
        0x200A: "HSP",            # Hair Space
        0x200B: "ZWSP",           # Zero Width Space
        0x202F: "NNBSP",          # Narrow No-Break Space
        0x205F: "MMSP",           # Medium Mathematical Space
        0x3000: "IDSP",           # Ideographic Space
        0xFEFF: "ZWNBSP",         # Zero Width No-Break Space (BOM)
    }
    if cp in whitespace_map:
        return f"U+{cp:04X}[{whitespace_map[cp]}]"

    # 4. BIDIRECTIONAL MARKS (invisible but affect rendering)
    bidi_map = {
        0x200E: "LRM",            # Left-to-Right Mark
        0x200F: "RLM",            # Right-to-Left Mark
        0x202A: "LRE",            # Left-to-Right Embedding
        0x202B: "RLE",            # Right-to-Left Embedding
        0x202C: "PDF",            # Pop Directional Formatting
        0x202D: "LRO",            # Left-to-Right Override
        0x202E: "RLO",            # Right-to-Left Override
        0x2066: "LRI",            # Left-to-Right Isolate
        0x2067: "RLI",            # Right-to-Left Isolate
        0x2068: "FSI",            # First Strong Isolate
        0x2069: "PDI",            # Pop Directional Isolate
    }
    if cp in bidi_map:
        return f"U+{cp:04X}[{bidi_map[cp]}]"

    # 5. ZERO-WIDTH JOINERS/NON-JOINERS (invisible, used for ligatures)
    if cp == 0x200C:
        return "U+200C[ZWNJ]"
    if cp == 0x200D:
        return "U+200D[ZWJ]"

    # 6. VARIATION SELECTORS (modify previous char rendering, invisible alone)
    if (0xFE00 <= cp <= 0xFE0F or      # Variation Selectors
        0xE0100 <= cp <= 0xE01EF):     # Variation Selectors Supplement
        return f"U+{cp:04X}[VS]"

    # 7. FORMAT CHARACTERS (formatting hints, not visible)
    format_map = {
        0x00AD: "SHY",            # Soft Hyphen
        0x034F: "CGJ",            # Combining Grapheme Joiner
        0x061C: "ALM",            # Arabic Letter Mark
        0x180E: "MVS",            # Mongolian Vowel Separator
        0x2060: "WJ",             # Word Joiner
        0x2061: "FUNC-APP",       # Function Application
        0x2062: "INV-TIMES",      # Invisible Times
        0x2063: "INV-SEP",        # Invisible Separator
        0x2064: "INV-PLUS",       # Invisible Plus
    }
    if cp in format_map:
        return f"U+{cp:04X}[{format_map[cp]}]"

    # 8. PRIVATE USE AREA (no standard glyph, system-dependent)
    if (0xE000 <= cp <= 0xF8FF or      # Private Use Area
        0xF0000 <= cp <= 0xFFFFD or    # Supplementary Private Use Area-A
        0x100000 <= cp <= 0x10FFFD):   # Supplementary Private Use Area-B
        return f"U+{cp:04X}[PUA]"

    # 9. NON-CHARACTERS (permanently reserved, invalid for interchange)
    if (cp & 0xFFFE == 0xFFFE or       # U+nFFFE and U+nFFFF
        0xFDD0 <= cp <= 0xFDEF):       # Non-characters in BMP
        return f"U+{cp:04X}[NONCHAR]"


    # 10. SURROGATES (UTF-16 artifacts, invalid in UTF-8)
    # This shouldn't occur in proper Python strings, but check anyway
    if 0xD800 <= cp <= 0xDFFF:
        return f"U+{cp:04X}[SURROGATE-INVALID]"

    # 11. UNASSIGNED CODE POINTS (valid range but no assigned character)
    # Check by attempting to get name
    try:
        unicodedata.name(symbol)
    except ValueError:
        return f"U+{cp:04X}[UNASSIGNED]"


    # 12. LINE/PARAGRAPH SEPARATORS (semantic whitespace, might break formatting)
    if cp == 0x2028:
        return "U+2028[LSEP]"
    if cp == 0x2029:
        return "U+2029[PSEP]"

    # If none of the problematic cases apply, return the symbol as-is
    return symbol


def is_comment_line(line: str) -> bool:
    """Check if line is a comment (starts with #)."""
    stripped = line.lstrip()
    return stripped.startswith('#')


def is_empty_line(line: str) -> bool:
    """Check if line is empty or whitespace only."""
    return not line.strip()


def is_header_delimiter(line: str) -> bool:
    """
    Check if line is a header delimiter (line of only # chars).

    Returns True if line contains only # and whitespace.
    """
    stripped = line.strip()
    return len(stripped) > 0 and all(c == '#' for c in stripped)

def parse_xcompose(file_content: str, source_file: str,
                   existing_trie: Optional[TrieNode] = None) -> Tuple[List[XComposeBlock], List[Collision]]:
    """
    Parse an XCompose file into blocks of entries, detecting collisions during parsing.
    If the XCompose is not delimited into blocks, return a single block with empty header.

    Args:
        file_content: Content of an XCompose file
        source_file: Path to the file being parsed
        existing_trie: Optional trie with pre-existing entries to check collisions against

    Returns:
        Tuple of (blocks, collisions)

    Raises:
        ParseError: On malformed lines
    """
    lines = file_content.split('\n')
    blocks: List[XComposeBlock] = []
    current_entries: List[XComposeEntry] = []
    current_header = ""

    # Initialize trie and collision list
    trie = existing_trie if existing_trie is not None else TrieNode()
    collisions = []

    i = 0
    while i < len(lines):
        line = lines[i]

        # Check for block header delimiter
        header = detect_block_header(lines, i)
        if header is not None:
            # Save current block if it has entries
            if current_entries:
                blocks.append(XComposeBlock(header=current_header, entries=current_entries))
                current_entries = []

            # Start new block with this header
            current_header = header
            i += 3  # Skip delimiter, header, and closing delimiter
            continue

        # Skip empty lines and comment lines (but not headers)
        if is_empty_line(line) or is_comment_line(line):
            i += 1
            continue

        # Try to parse as XCompose entry
        entry = parse_line(line, i + 1, source_file)  # line_number is 1-indexed
        if entry is not None:
            # Check for collisions and add to trie
            entry_collisions = check_and_add_to_trie(entry, trie)
            collisions.extend(entry_collisions)
            current_entries.append(entry)

        i += 1

    # Add final block if it has entries
    if current_entries:
        blocks.append(XComposeBlock(header=current_header, entries=current_entries))

    # If no blocks were created, return a single empty block
    if not blocks:
        blocks.append(XComposeBlock(header="", entries=[]))

    return blocks, collisions


def detect_block_header(lines: List[str], index: int) -> Optional[str]:
    """
    Check if current position is a block header delimiter.

    A block header is:
    - Line of only # characters
    - Followed by a comment line (the header text)
    - Followed by another line of only # characters

    Args:
        lines: All lines from file
        index: Current line index

    Returns:
        Header text if this is a block delimiter, None otherwise
    """
    # Need at least 3 lines: delimiter, header, delimiter
    if index + 2 >= len(lines):
        return None

    line1 = lines[index]
    line2 = lines[index + 1]
    line3 = lines[index + 2]

    # Check pattern: ###, # HEADER #, ###
    if (is_header_delimiter(line1) and
        is_comment_line(line2) and
        is_header_delimiter(line3)):
        # Extract header text (remove # and whitespace)
        header = line2.strip('#').strip()
        return header

    return None


def parse_line(line: str, line_number: int, source_file: str) -> Optional[XComposeEntry]:
    """
    Parse single XCompose line.

    Expected format:
    <Multi_key><key1><key2>... : "symbol" # optional comment

    The syntax is liberal:
    - Keys can have no spaces between them
    - Symbol string can contain <>, ", escaped quotes, etc.
    - Comment can contain anything

    Args:
        line: Raw line from file
        line_number: Line number for error reporting
        source_file: Source file path for tracking

    Returns:
        XComposeEntry if valid XCompose line

    Raises:
        ParseError: If line is malformed XCompose syntax
    """
    # Split on first colon
    parts = line.split(':', 1)
    if len(parts) < 2:
        raise ParseError(line_number, line, "Missing colon separator")

    left = parts[0].strip()
    right = ":".join(parts[1:]).strip()

    # Extract keys (including Multi_key)
    keys = extract_keys(left)

    # Extract symbol from quoted string
    symbol = extract_quoted_string(right)

    # Get Unicode info
    if len(symbol) == 1:
        # Single character: get unicode info from unicodedata
        unicode_point, description = extract_unicode_info(symbol)
    else:
        # Multi-character: extract comment from original line
        comment = extract_comment(right)
        unicode_point = ""
        description = comment if comment else "MULTI-CHAR"

    return XComposeEntry(
        keys=keys,
        symbol=symbol,
        unicode_point=unicode_point,
        description=description,
        source_file=source_file,
        line_number=line_number
    )


def extract_keys(key_sequence: str) -> List[str]:
    """
    Extract individual keys from key sequence string.

    Handles liberal syntax: <Multi_key><a><b> or <Multi_key> <a> <b>
    Also handles sequences with dead keys (e.g., system Compose file)

    Args:
        key_sequence: String like "<Multi_key><i><a>" or "<dead_tilde> <space>"

    Returns:
        List of ALL keys: ["Multi_key", "i", "a"] or ["dead_tilde", "space"]
    """
    keys = []
    i = 0

    while i < len(key_sequence):
        if key_sequence[i] == '<':
            # Find matching >
            close_idx = key_sequence.find('>', i)
            if close_idx == -1:
                raise ValueError(f"Unclosed angle bracket at position {i}")

            key = key_sequence[i+1:close_idx]
            keys.append(key)

            i = close_idx + 1
        else:
            # Skip whitespace and other chars between brackets
            i += 1

    return keys


def extract_quoted_string(text: str) -> str:
    """
    Extract quoted string from text, handling escape sequences.

    Args:
        text: String starting with '"' (possibly with leading whitespace)

    Returns:
        The content of the quoted string (without quotes, with escapes processed)

    Raises:
        ValueError: If no quoted string found or unclosed quote
    """
    text = text.lstrip()

    if not text.startswith('"'):
        raise ValueError("Text must start with quote")

    i = 1  # Start after opening quote
    result = []

    while i < len(text):
        ch = text[i]

        if ch == '\\' and i + 1 < len(text):
            # Escape sequence - take next char literally
            next_ch = text[i + 1]
            result.append(next_ch)
            i += 2
        elif ch == '"':
            # Unescaped quote - end of string
            return ''.join(result)
        else:
            result.append(ch)
            i += 1

    raise ValueError("Unclosed quoted string")


def extract_comment(text: str) -> str:
    """
    Extract comment from text after quoted string.

    Args:
        text: String like '"symbol" # COMMENT' or '"symbol"'

    Returns:
        Comment text (without leading #) or empty string if no comment
    """
    # Skip past the quoted string first
    text = text.lstrip()
    if not text.startswith('"'):
        return ""

    i = 1  # Start after opening quote
    while i < len(text):
        ch = text[i]
        if ch == '\\' and i + 1 < len(text):
            i += 2
        elif ch == '"':
            # Found end of quoted string
            remaining = text[i+1:].lstrip()
            if remaining.startswith('#'):
                return remaining[1:].strip()
            return ""
        else:
            i += 1

    return ""


def format_blocks(blocks: List[XComposeBlock]) -> str:
    """
    Format multiple blocks with headers.

    Args:
        blocks: List of blocks to format

    Returns:
        Formatted XCompose text
    """
    result = []

    for block in blocks:
        result.append(format_block(block))

    return '\n'.join(result)


def format_block(block: XComposeBlock) -> str:
    """
    Format single block with aligned columns.

    Args:
        block: Block to format

    Returns:
        Formatted XCompose text with header and aligned entries
    """
    lines = []

    # Add header if present
    if block.header:
        delimiter = '#' * (len(block.header) + 4)
        lines.append(delimiter)
        lines.append(f"# {block.header} #")
        lines.append(delimiter)
        lines.append("")

    # Calculate alignment width for this block
    key_width = max(len(format_key_sequence(entry.keys)) for entry in block.entries)

    # Format each entry
    for entry in block.entries:
        lines.append(format_entry(entry, key_width))

    return '\n'.join(lines)


def format_entry(entry: XComposeEntry, key_width: int) -> str:
    """
    Format single entry with padding.

    Args:
        entry: Entry to format
        key_width: Width to pad key sequence to

    Returns:
        Formatted line like: <Multi_key> <i> <a>    : "ð‘Ž" U1D44E # MATHEMATICAL ITALIC SMALL A
    """
    key_seq = format_key_sequence(entry.keys)
    padding = ' ' * (key_width - len(key_seq))

    return f'{key_seq}{padding} : "{entry.symbol}" {entry.unicode_point} # {entry.description}'



def format_key_sequence(keys: KeySequence) -> str:
    """
    Format key list as XCompose sequence: <key0> <key1> <key2>

    Args:
        keys: List of ALL keys (including first key like Multi_key, dead_tilde, etc.)

    Returns:
        Formatted key sequence string like "<Multi_key> <i> <a>" or "<dead_tilde> <space>"
    """
    return ' '.join([f'<{key}>' for key in keys])


def transliterate_blocks(blocks: List[XComposeBlock],
                        translit_map: TranslitMap) -> List[XComposeBlock]:
    """
    Transliterate all blocks, filtering unchanged entries.

    Args:
        blocks: Original blocks
        translit_map: Key mapping (QWERTY â†’ Cyrillic)

    Returns:
        Transliterated blocks with only changed entries
    """
    result_blocks = []

    for block in blocks:
        transliterated_entries = []

        for entry in block.entries:
            # Apply transliteration to keys
            transliterated_keys = [translit_map.get(key, key) for key in entry.keys]

            # Only include if keys changed
            if transliterated_keys != entry.keys:
                transliterated_entries.append(XComposeEntry(
                    keys=transliterated_keys,
                    symbol=entry.symbol,
                    unicode_point=entry.unicode_point,
                    description=entry.description,
                    source_file=entry.source_file,
                    line_number=entry.line_number
                ))

        # Only include block if it has changed entries
        if transliterated_entries:
            result_blocks.append(XComposeBlock(
                header=block.header,
                entries=transliterated_entries
            ))

    return result_blocks


def get_current_locale() -> str:
    """
    Get current system locale (e.g., en_US.UTF-8).

    Returns:
        Locale string or "en_US.UTF-8" as fallback
    """
    # Try environment variables first
    for var in ['LC_ALL', 'LC_CTYPE', 'LANG']:
        loc = os.environ.get(var)
        if loc:
            return loc

    # Try Python's locale module
    loc, _ = locale.getlocale()
    if loc:
        return loc

    # Fallback
    raise Exception("Could not determine system locale")


def load_system_compose(locale_name: str) -> Optional[List[XComposeEntry]]:
    """
    Load system XCompose file for locale.

    Args:
        locale_name: System locale (e.g., "en_US.UTF-8"), or None to auto-detect

    Returns:
        List of parsed entries, or None if not found/parse error
    """

    # Common locations for system Compose files
    paths = [
        Path(f"/usr/share/X11/locale/{locale_name}/Compose"),
        Path(f"/usr/share/X11/locale/{locale_name.split('.')[0]}/Compose")
    ]

    for path in paths:
        if path.exists():
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    content = f.read()
                blocks, _ = parse_xcompose(content, str(path))  # Ignore collisions within system file
                # Flatten all entries from all blocks
                entries = []
                for block in blocks:
                    entries.extend(block.entries)
                # Only return if we got at least some entries
                if entries:
                    return entries
            except Exception as e:
                # Parse errors are common in system files (includes, etc.)
                # Try next path
                continue

    return None


def find_all_terminal_descendants(node: TrieNode) -> List[XComposeEntry]:
    """
    Find all terminal entries in the subtree rooted at node.

    Args:
        node: Root of subtree to search

    Returns:
        List of all XComposeEntry objects found in descendants
    """
    terminals = []

    for key, child in node.children.items():
        # Check if child is terminal
        if child.entry is not None:
            terminals.append(child.entry)

        # Recursively search descendants
        terminals.extend(find_all_terminal_descendants(child))

    return terminals


def build_trie(entries: List[XComposeEntry]) -> TrieNode:
    """
    Build prefix tree from entries.

    Args:
        entries: All XCompose entries

    Returns:
        Root node of trie
    """
    root = TrieNode()

    for entry in entries:
        node = root
        for key in entry.keys:
            if key not in node.children:
                node.children[key] = TrieNode()
            node = node.children[key]

        # Mark this as a terminal node
        node.entry = entry

    return root


def check_and_add_to_trie(entry: XComposeEntry, trie: TrieNode) -> List[Collision]:
    """
    Check entry for collisions against trie, then add it to the trie.

    Args:
        entry: Entry to check and add
        trie: Root of the prefix tree

    Returns:
        List of collisions found
    """
    collisions = []
    node = trie

    # Traverse the trie following the entry's key sequence
    for i, key in enumerate(entry.keys):
        # Check if we hit a terminal node before the end
        # This means an existing entry is a prefix of current entry
        if node.entry is not None and i < len(entry.keys):
            existing_entry = node.entry
            collisions.append(Collision(
                prefix_seq=existing_entry.keys,
                prefix_entry=existing_entry,
                prefix_source_file=existing_entry.source_file,
                longer_entry=entry,
                longer_source_file=entry.source_file
            ))

        # Create path if it doesn't exist
        if key not in node.children:
            node.children[key] = TrieNode()
        node = node.children[key]

    # Check if current entry is a prefix of existing entries
    descendants = find_all_terminal_descendants(node)
    for longer_entry in descendants:
        collisions.append(Collision(
            prefix_seq=entry.keys,
            prefix_entry=entry,
            prefix_source_file=entry.source_file,
            longer_entry=longer_entry,
            longer_source_file=longer_entry.source_file
        ))

    # Mark this as a terminal node
    node.entry = entry

    return collisions



def report_collisions(collisions: List[Collision], out=sys.stderr) -> None:
    """
    Report collisions to stderr.

    Args:
        collisions: List of detected collisions
        out: Output stream (default stderr)
    """
    if not collisions:
        return

    out.write(f"\n{'='*60}\n")
    out.write(f"WARNING: {len(collisions)} PREFIX COLLISION(S) DETECTED\n")
    out.write(f"{'='*60}\n\n")

    for i, collision in enumerate(collisions, 1):
        out.write(f"Collision #{i}:\n")
        out.write(f"  Prefix sequence: {format_key_sequence(collision.prefix_seq)}\n")
        out.write(f"    Line {collision.prefix_entry.line_number}, {collision.prefix_source_file}\n")
        out.write(f"    Symbol: {escape_symbol(collision.prefix_entry.symbol)}\n")
        out.write(f"  Is prefix of: {format_key_sequence(collision.longer_entry.keys)}\n")
        out.write(f"    Line {collision.longer_entry.line_number}, {collision.longer_source_file}\n")
        out.write(f"    Symbol: {escape_symbol(collision.longer_entry.symbol)}\n")
        out.write("\n")

    out.write(f"{'='*60}\n\n")


def main() -> int:
    """
    Main entry point for XCompose generator.

    Returns:
        Exit code (0 = success, 1 = error, 2 = collisions with --strict)
    """
    parser = argparse.ArgumentParser(
        description='Generate XCompose configuration with Russian transliteration and collision detection'
    )
    parser.add_argument(
        '--input',
        type=Path,
        default=Path('XCompose-draft'),
        help='Source XCompose-draft file (default: XCompose-draft)'
    )
    parser.add_argument(
        '--output',
        type=Path,
        default=None,
        help='Output XCompose file (default: stdout)'
    )
    parser.add_argument(
        '--translit',
        type=Path,
        default=Path('parallel-symbols.json'),
        help='Transliteration map JSON file (default: parallel-symbols.json)'
    )
    parser.add_argument(
        '--locale',
        type=str,
        default=None,
        help='System locale for collision checking (default: auto-detect)'
    )
    parser.add_argument(
        '--check-only',
        action='store_true',
        help='Only check for collisions, don\'t generate output'
    )
    parser.add_argument(
        '--strict',
        action='store_true',
        help='Exit with error code if collisions detected'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Show verbose parsing details'
    )
    parser.add_argument(
        '--no-system-check',
        action='store_true',
        help='Skip cross-system collision detection'
    )

    args = parser.parse_args()

    # Load system Compose first for collision detection
    system_trie = None
    if not args.no_system_check:
        locale_name = args.locale if args.locale else get_current_locale()
        if args.verbose:
            print(f"Loading system Compose for locale: {locale_name}...", file=sys.stderr)
        system_entries = load_system_compose(locale_name)
        if system_entries:
            if args.verbose:
                print(f"Loaded {len(system_entries)} system entries", file=sys.stderr)
            # Build trie from system entries
            system_trie = build_trie(system_entries)

    # Parse XCompose-draft with collision detection
    if args.verbose:
        print(f"Reading {args.input}...", file=sys.stderr)

    with open(args.input, 'r', encoding='utf-8') as f:
        content = f.read()
    blocks, collisions = parse_xcompose(content, str(args.input), system_trie)

    # Flatten entries for reporting
    entries = []
    for block in blocks:
        entries.extend(block.entries)

    if args.verbose:
        print(f"Parsed {len(entries)} entries from {len(blocks)} blocks", file=sys.stderr)
        if collisions:
            print(f"Found {len(collisions)} collisions", file=sys.stderr)

    # Report collisions
    if collisions:
        report_collisions(collisions, sys.stderr)

    # Exit if check-only
    if args.check_only:
        if collisions:
            return 2 if args.strict else 0
        return 0

    # Exit with error if strict mode and collisions found
    if args.strict and collisions:
        return 2

    # Load transliteration map
    translit_map = {}
    if args.translit.exists():
        with open(args.translit, 'r', encoding='utf-8') as f:
            translit_map = json.load(f)
        if args.verbose:
            print(f"Loaded transliteration map with {len(translit_map)} entries", file=sys.stderr)
    else:
        if args.verbose:
            print(f"Warning: Transliteration file not found: {args.translit}", file=sys.stderr)

    # Open output stream
    if args.output:
        out = open(args.output, 'w', encoding='utf-8')
    else:
        out = sys.stdout

    # Write include directive
    out.write('include "%L"\n\n')

    # Write base version
    out.write(format_blocks(blocks))
    out.write('\n\n')

    # Write transliterated version if we have a map
    if translit_map:
        out.write('########################################\n')
        out.write('#      RUSSIAN TRANSLIT VERSION        #\n')
        out.write('########################################\n\n')

        trans_blocks = transliterate_blocks(blocks, translit_map)
        out.write(format_blocks(trans_blocks))

    if args.output:
        out.close()
        if args.verbose:
            print(f"Output written to {args.output}", file=sys.stderr)

    return 0


if __name__ == '__main__':
    sys.exit(main())
